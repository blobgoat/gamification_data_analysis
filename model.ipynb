{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET UP AND VARIABLE DEFINITONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_functions.spreadsheet_specific_helpers' from 'c:\\\\kelly\\\\School\\\\Colleage\\\\24-25\\\\seal\\\\gamification_data_analysis\\\\helper_functions\\\\spreadsheet_specific_helpers.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set up\n",
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, MultiTaskLassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 50\n",
    "import helper_functions.spreadsheet_specific_helpers as helper\n",
    "import importlib\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHEETURL: str = (\n",
    "    \"https://docs.google.com/spreadsheets/d/\"\n",
    "    \"1XcR48HZuC-mSFB-uKIxwPFhfRGVX7bWy100PhcLA8oM/\"\n",
    "    \"edit?resourcekey=&gid=1780925762#gid=1780925762\"\n",
    ")\n",
    "\n",
    "# format for CSV https://docs.google.com/spreadsheets/d/\n",
    "# <SHEET_ID>/gviz/tq?tqx=\n",
    "# out:csv&sheet=<SHEET_NAME>\n",
    "SHEET_CSV_URL: str = (\n",
    "    \"https://docs.google.com/spreadsheets/d/\"\n",
    "    \"1XcR48HZuC-mSFB-uKIxwPFhfRGVX7bWy100PhcLA8oM/\"\n",
    "    \"gviz/tq?tqx=out:csv&sheet=Congregated Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# global variables for our current data purposes\n",
    "Y_COLS = [\n",
    "    \"On a scale of 1 - 5 how successful do you feel you are in SEAL lab?\",\n",
    "    \"On a scale of 1 - 5, how successful to do you feel your teammates are in SEAL lab?\",\n",
    "    \"On a scale of 1 - 5, how successful do your peers think you are in SEAL lab?\",\n",
    "    \"On whole, how would you rate your satisfaction in SEAL lab?\"\n",
    "]\n",
    "\n",
    "X_DEMO_COLS = [\n",
    "    \"Main SEAL group affiliation\",\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    \"Sexual orientation\",\n",
    "    \"Race\",\n",
    "    \"Chronic condition\",\n",
    "    \"Condition description\",\n",
    "    \"Economic class\",\n",
    "    \"Religion\"\n",
    "]\n",
    "\n",
    "X_PERSONALITY_COLS = [\n",
    "    \"Internal / External game motivation\",\n",
    "    \"[Introverted - Extroverted]\",\n",
    "    \"[Critical - Trusting]\",\n",
    "    \"[Spontaneous - Conscientious]\",\n",
    "    \"[Self-conscious - Even-tempered]\",\n",
    "    \"[Prefer similarity - Am open to change]\"\n",
    "]\n",
    "MOTIVATION_COLS = [\n",
    "    \"Beating my competitors\",\n",
    "    \"Mastering the game\",\n",
    "    \"Earning the most points\",\n",
    "    \"Working with a team\",\n",
    "    \"Feeling immersed in the story/plot\"\n",
    "]\n",
    "\n",
    "X_SEAL_COLS = [\n",
    "    \"I feel like I am playing a game\",\n",
    "    \"I consider myself to be highly experienced.\",\n",
    "    \"Aesthetically pleasing.\",\n",
    "    \"Rank reflects work accurately.\",\n",
    "    \"Leaderboard reflects work accurately.\",\n",
    "    \"YBR reflects work accurately.\",\n",
    "    \"VisTools reflects work accurately.\",\n",
    "    \"RaceTrack reflects work accurately.\",\n",
    "    \"Battle Station reflects work accurately.\",\n",
    "    \"Command Center reflects work accurately.\",\n",
    "    \"I understand what my SEAL statistics mean.\",\n",
    "    \"I know exactly how my actions affect my lab statistics\",\n",
    "    \"Using the Sudoku Sheet Tools helps me and my team stay on track.\",\n",
    "    \"Using the Sudoku Sheet Tools encourages me to take risks and challenge myself.\",\n",
    "    \"Using the Sudoku Sheet Tools makes my work in SEAL more enjoyable.\"\n",
    "]\n",
    "# AO:AX\n",
    "X_USABILITY_COLS = [\n",
    "    'I think that I would like to use this system frequently',\n",
    "    'I found the system unnecessarily complex',\n",
    "    'I thought the system was easy to use',\n",
    "    'I think that I would need the support of a technical person to be able to use this system',\n",
    "    'I found the various functions in this system were well integrated',\n",
    "    'I thought there was too much inconsistency in this system',\n",
    "    'I would imagine that most people would learn to use this system very quickly',\n",
    "    'I found the system very cumbersome to use',\n",
    "    'I felt very confident using the system',\n",
    "    'I needed to learn a lot of things before I could get going with this system.']\n",
    "\n",
    "Y_COLS = [\"Personal success\",\n",
    "          \"Teammate success\",\n",
    "          \"Peer success\",\n",
    "          \"Satisfaction in SEAL\"\n",
    "]\n",
    "\n",
    "X_DROP_COLS = ['All SEAL group affiliations', 'Game motivation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data() -> DataFrame:  # idealy we dont want to us Any, but for now\n",
    "    \"\"\"function to get the data from the google sheet\n",
    "    raises: HTTPError: if the request fails (meaning url wrong or no inter)\n",
    "\n",
    "    @returns: @type(DataFrame): the data from the google sheet\"\"\"\n",
    "\n",
    "    response = requests.get(SHEET_CSV_URL)\n",
    "    response.raise_for_status()  # Raise error if request fails\n",
    "    df: DataFrame = pd.read_csv(io.StringIO(response.text))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Main SEAL group affiliation', 'All SEAL group affiliations',\n",
      "       'Developed for SUDOKU Sheet Tools?', 'Age', 'Gender',\n",
      "       'Sexual orientation', 'Race', 'Chronic condition',\n",
      "       'Condition description', 'Economic class', 'Religion',\n",
      "       'Game motivation', 'Internal / External game motivation',\n",
      "       '[Introverted - Extroverted]', '[Critical - Trusting]',\n",
      "       '[Spontaneous - Conscientious]', '[Self-conscious - Even-tempered]',\n",
      "       '[Prefer similarity - Am open to change]',\n",
      "       'I feel like I am playing a game',\n",
      "       'I consider myself to be highly experienced.',\n",
      "       'Aesthetically pleasing.', 'Rank reflects work accurately.',\n",
      "       'Leaderboard reflects work accurately.',\n",
      "       'YBR reflects work accurately.', 'VisTools reflects work accurately.',\n",
      "       'RaceTrack reflects work accurately.',\n",
      "       'Battle Station reflects work accurately.',\n",
      "       'Command Center reflects work accurately.',\n",
      "       'I understand what my SEAL statistics mean.',\n",
      "       'I know exactly how my actions affect my lab statistics',\n",
      "       'Using the Sudoku Sheet Tools helps me and my team stay on track.',\n",
      "       'Using the Sudoku Sheet Tools encourages me to take risks and challenge myself.',\n",
      "       'Using the Sudoku Sheet Tools makes my work in SEAL more enjoyable.',\n",
      "       'Personal success', 'Teammate success', 'Peer success',\n",
      "       'Satisfaction in SEAL',\n",
      "       'I think that I would like to use this system frequently',\n",
      "       'I found the system unnecessarily complex',\n",
      "       'I thought the system was easy to use',\n",
      "       'I think that I would need the support of a technical person to be able to use this system',\n",
      "       'I found the various functions in this system were well integrated',\n",
      "       'I thought there was too much inconsistency in this system',\n",
      "       'I would imagine that most people would learn to use this system very quickly',\n",
      "       'I found the system very cumbersome to use',\n",
      "       'I felt very confident using the system',\n",
      "       'I needed to learn a lot of things before I could get going with this system.'],\n",
      "      dtype='object')\n",
      "(81, 47)\n"
     ]
    }
   ],
   "source": [
    "## ORIGINAL\n",
    "data = get_data()\n",
    "columns = data.columns\n",
    "print(columns)\n",
    "print(data.shape) # 81 x 47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(data) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"function to split the x and y data into separate ndarrays based on\n",
    "    a set of columns to be dropped\n",
    "\n",
    "    @parameter: data @type(DataFrame): rawdata\n",
    "\n",
    "    @returns: @type(ndarray): relevant x-values from data\n",
    "    @returns: @type(ndarray): y-values from data\"\"\"\n",
    "    \n",
    "    split_col: DataFrame = helper.split_motivation_column(data)\n",
    "    x_data = data.drop(columns=X_DROP_COLS + Y_COLS)    # split motivation columns\n",
    "    x_data = pd.concat([x_data, split_col], axis=1)\n",
    "\n",
    "    # handle X_SEAL_COLS: map disagree - agree as 1-5\n",
    "    options_map = {'Strongly disagree': 1,\n",
    "                    'Disagree': 2,\n",
    "                    'Neutral': 3,\n",
    "                    'Agree': 4,\n",
    "                    'Strongly agree': 5\n",
    "                    }\n",
    "    x_data[X_SEAL_COLS] = x_data[X_SEAL_COLS].replace(options_map)\n",
    "\n",
    "    # Handle NaNs with data imputation of average\n",
    "    x_data[X_PERSONALITY_COLS[1:]] = x_data[X_PERSONALITY_COLS[1:]].fillna(3)\n",
    "    x_data[X_SEAL_COLS] = x_data[X_SEAL_COLS].fillna(3)\n",
    "    x_data[X_USABILITY_COLS] = x_data[X_USABILITY_COLS].fillna(3)\n",
    "    data[Y_COLS] = data[Y_COLS].fillna(3)\n",
    "\n",
    "    # one-hot-encoding for categorical data (demographics, gaming)\n",
    "    cat_col = x_data.select_dtypes(include=['object', 'category']).columns\n",
    "    x_data = pd.get_dummies(x_data, columns = cat_col)\n",
    "    y_data = data[Y_COLS]\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x_train, x_test) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"function that standardizes data to normal gaussian distribution.\n",
    "    Standardization calculation is applied only to the training data.\n",
    "\n",
    "    @parameter: x_train @type(nd.array) processed x training data to be standardized\n",
    "    @paremeter: x_test @type(nd.array) processed x-test data to be standardized\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler().fit(x_train)  # only fit on training data\n",
    "    x_train_stand = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "    x_test_stand = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns, index=x_test.index)\n",
    "    return x_train_stand, x_test_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multitask_lasso_path(x_train, y_train):\n",
    "    lasso_cv = MultiTaskLassoCV(alphas=np.logspace(-4, 0, 100), cv=5, random_state=12)\n",
    "    lasso_cv.fit(x_train, y_train)\n",
    "\n",
    "    # lasso_cv.coef_ is shape (n_targets, n_features)\n",
    "    # To plot, we show coefficient magnitudes across alphas for each target separately\n",
    "\n",
    "    alphas = lasso_cv.alphas_\n",
    "    n_targets = y_train.shape[1]\n",
    "\n",
    "    for task_idx in range(n_targets):\n",
    "        coefs = []\n",
    "        for alpha in alphas:\n",
    "            lasso = MultiTaskLassoCV(alphas=[alpha], cv=5, random_state=12)\n",
    "            lasso.fit(x_train, y_train)\n",
    "            coefs.append(lasso.coef_[task_idx])\n",
    "\n",
    "        coefs = np.array(coefs)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i in range(coefs.shape[1]):\n",
    "            plt.plot(np.log10(alphas), coefs[:, i], label=x_train.columns[i])\n",
    "\n",
    "        plt.xlabel(\"log10(alpha)\")\n",
    "        plt.ylabel(f\"Coefficients (Target {task_idx+1})\")\n",
    "        plt.title(f\"LASSO Path for Target {task_idx+1}\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(x_train, y_train):\n",
    "    \"\"\"function to apply LASSO regression on training data to select optimal\n",
    "    features.\n",
    "\n",
    "    @parameter: x_train @type(nd.array) standardized x_train data\n",
    "    @parameter: y_train @type(nd.array) y_train data\"\"\"\n",
    "\n",
    "    # perform 5-fold cross validation on lasso values\n",
    "    lasso = MultiTaskLassoCV(alphas=np.logspace(-4, 0, 100), cv=5, random_state=12)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    best_l1 = lasso.alpha_\n",
    "    non_zero_indices = np.abs(lasso.coef_) >= 1e-8\n",
    "\n",
    "    top_features = []\n",
    "    eliminated_features = []\n",
    "\n",
    "    for i, feature in enumerate(x_train.columns):\n",
    "        if np.any(non_zero_indices[:, i]):\n",
    "            top_features.append(feature)\n",
    "        else:\n",
    "            eliminated_features.append(feature)\n",
    "    return x_train[top_features], best_l1, eliminated_features, top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelly\\AppData\\Local\\Temp\\ipykernel_30004\\3779065999.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  x_data[X_SEAL_COLS] = x_data[X_SEAL_COLS].replace(options_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 90) (68, 4)\n",
      "(13, 90) (13, 4)\n",
      "(68, 90)\n",
      "0.1873817422860385\n",
      "eliminated 66 ['[Critical - Trusting]', '[Spontaneous - Conscientious]', '[Prefer similarity - Am open to change]', 'I feel like I am playing a game', 'Aesthetically pleasing.', 'Rank reflects work accurately.', 'Leaderboard reflects work accurately.', 'VisTools reflects work accurately.', 'Battle Station reflects work accurately.', 'Command Center reflects work accurately.', 'I understand what my SEAL statistics mean.', 'I know exactly how my actions affect my lab statistics', 'Using the Sudoku Sheet Tools helps me and my team stay on track.', 'Using the Sudoku Sheet Tools encourages me to take risks and challenge myself.', 'Using the Sudoku Sheet Tools makes my work in SEAL more enjoyable.', 'I found the system unnecessarily complex', 'I thought the system was easy to use', 'I think that I would need the support of a technical person to be able to use this system', 'I found the various functions in this system were well integrated', 'I thought there was too much inconsistency in this system', 'I would imagine that most people would learn to use this system very quickly', 'I found the system very cumbersome to use', 'I needed to learn a lot of things before I could get going with this system.', 'Beating my competitors', 'Mastering the game', 'Earning the most points', 'Feeling immersed in the story/plot', 'Main SEAL group affiliation_Biz/Tech', 'Main SEAL group affiliation_Plasma', 'Developed for SUDOKU Sheet Tools?_Never', 'Developed for SUDOKU Sheet Tools?_No Response', 'Developed for SUDOKU Sheet Tools?_Yes, but not last quarter or this quarter.', 'Age_High school', 'Age_No Response', 'Age_Undergrad', 'Gender_Female', 'Gender_No Response', 'Gender_Other', 'Sexual orientation_Bisexual', 'Sexual orientation_Heterosexual or straight', 'Sexual orientation_Heterosexual or straight, Teaching Team', 'Sexual orientation_No Response', 'Race_American Indian or Alaska Native (E.g. Navajo Nation, Blackfeet Tribe, Mayan, Aztec, Native Village of Barrow Inuplat Tradiational Government, Nome Eskimo Community), White (E.g. German, Irish, English, Italian, Polish, French)', 'Race_Asian  (E.g. Chinese, Filipino, Asian Indian, Vietnamese, Korean, Japanese)', 'Race_Black or African American (E.g. Jamaican, Haitian, Nigerian, Ethiopian, Somalian)', 'Race_I prefer not to answer', 'Race_No Response', 'Race_White (E.g. German, Irish, English, Italian, Polish, French)', 'Chronic condition_No', 'Chronic condition_No Response', 'Condition description_Depression, ADHD', 'Condition description_Diabetic', 'Condition description_No', 'Economic class_Affluent', 'Economic class_Middle Class', 'Economic class_No Response', 'Economic class_Poor', 'Economic class_Working Class', 'Economic class_Working Class, Middle Class', 'Religion_Agnostic', 'Religion_Atheist', 'Religion_Hindu', 'Religion_Muslim', 'Internal / External game motivation_Equally motivated by external and internal factors', 'Internal / External game motivation_Highly motivated by external rewards (e.g. leaderboard, badges, etc.)', 'Internal / External game motivation_Highly motivated by internal rewards (e.g. improving my own skills, learning)']\n",
      "kept 24 ['[Introverted - Extroverted]', '[Self-conscious - Even-tempered]', 'I consider myself to be highly experienced.', 'YBR reflects work accurately.', 'RaceTrack reflects work accurately.', 'I think that I would like to use this system frequently', 'I felt very confident using the system', 'Working with a team', 'Main SEAL group affiliation_Embedded', 'Main SEAL group affiliation_ITAC', 'Main SEAL group affiliation_Sudoku', 'Developed for SUDOKU Sheet Tools?_Yes', 'Age_Post Grad', 'Gender_Male', 'Sexual orientation_Gay or lesbian', 'Race_Asian  (E.g. Chinese, Filipino, Asian Indian, Vietnamese, Korean, Japanese), White (E.g. German, Irish, English, Italian, Polish, French)', 'Race_Middle Eastern or North African (E.g. Lebanese, Iranian, Egyptian, Syrian, Moroccan, Algerian)', 'Chronic condition_Prefer not to answer', 'Chronic condition_Yes', 'Condition description_No Response', 'Economic class_Middle Class, Affluent', 'Religion_Buddhist', 'Religion_Christian', 'Religion_No Response']\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = split_xy(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state = 12)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "x_train, x_test = standardize(x_train, x_test)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train_reduced, l1, eliminated_features, top_features = feature_selection(x_train, y_train)\n",
    "print(l1)\n",
    "print(f'eliminated {len(eliminated_features)} {eliminated_features}')\n",
    "print(f'kept {len(top_features)} {top_features}')\n",
    "x_test_reduced = x_test[top_features]\n",
    "\n",
    "#plot_multitask_lasso_path(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 47)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['All SEAL group affiliations'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m data_no_demo \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mX_DEMO_COLS)\n\u001b[1;32m----> 4\u001b[0m x_no_demo_data, y_no_demo_data \u001b[38;5;241m=\u001b[39m split_xy(data_no_demo)\n\u001b[0;32m      5\u001b[0m x_NDtrain, x_NDtest, y_NDtrain, y_NDtest \u001b[38;5;241m=\u001b[39m train_test_split(x_no_demo_data, y_no_demo_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_NDtrain\u001b[38;5;241m.\u001b[39mshape, y_NDtrain\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36msplit_xy\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"function to split the x and y data into separate ndarrays based on\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03ma set of columns to be dropped\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m@returns: @type(ndarray): relevant x-values from data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m@returns: @type(ndarray): y-values from data\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m split_col: DataFrame \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39msplit_motivation_column(data)\n\u001b[1;32m---> 11\u001b[0m x_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mX_DROP_COLS \u001b[38;5;241m+\u001b[39m Y_COLS)    \u001b[38;5;66;03m# split motivation columns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m x_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([x_data, split_col], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# handle X_SEAL_COLS: map disagree - agree as 1-5\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kelly\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kelly\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\kelly\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kelly\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['All SEAL group affiliations'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## Non-demographic data\n",
    "print(data.shape)\n",
    "data_no_demo = data.drop(columns=X_DEMO_COLS)\n",
    "x_no_demo_data, y_no_demo_data = split_xy(data_no_demo)\n",
    "x_NDtrain, x_NDtest, y_NDtrain, y_NDtest = train_test_split(x_no_demo_data, y_no_demo_data, test_size=0.15, random_state = 12)\n",
    "\n",
    "print(x_NDtrain.shape, y_NDtrain.shape)\n",
    "print(x_NDtest.shape, y_NDtest.shape)\n",
    "\n",
    "x_NDtrain, x_NDtest = standardize(x_NDtrain, x_NDtest)\n",
    "print(x_NDtrain.shape)\n",
    "\n",
    "x_train_reducedND, l1ND, eliminated_featuresND, top_featuresND = feature_selection(x_NDtrain, y_NDtest)\n",
    "print(l1ND)\n",
    "print(f'eliminated {len(eliminated_featuresND)} {eliminated_featuresND}')\n",
    "print(f'kept {len(top_featuresND)} {top_featuresND}')\n",
    "x_train_reducedND = x_NDtest[top_featuresND]\n",
    "\n",
    "#plot_multitask_lasso_path(x_NDtrain, y_NDtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x_train, y_train, x_val, y_val):\n",
    "    models = []\n",
    "    train_rmse = []\n",
    "    val_rmse = []\n",
    "    for i in range(y_train.shape[1]):\n",
    "        y_t = y_train.iloc[:,i]\n",
    "        y_v = y_val.iloc[:,i]\n",
    "        model = LinearRegression().fit(x_train, y_t)\n",
    "        predict_t = model.predict(x_train)\n",
    "        t_rmse = np.sqrt(mean_squared_error(y_t, predict_t))\n",
    "        predict_v = model.predict(x_val)\n",
    "        v_rmse = np.sqrt(mean_squared_error(y_v, predict_v))\n",
    "\n",
    "        train_rmse.append(t_rmse)\n",
    "        val_rmse.append(v_rmse)\n",
    "        models.append(model)\n",
    "    print(x_train.columns)\n",
    "    linear_visualization(models, x_train.columns, y_train.columns)\n",
    "    return models, train_rmse, val_rmse\n",
    "\n",
    "def linear_visualization(models, features, y_cols):\n",
    "    for i, model in enumerate(models):\n",
    "        coef = model.coef_\n",
    "\n",
    "        coef_list = pd.DataFrame({\"Feature\": features, \"Coef\": coef})\n",
    "        coef_list[\"abs\"] = coef_list[\"Coef\"].abs()\n",
    "        top = coef_list.nlargest(10, \"abs\")\n",
    "        print(top[\"Feature\"], top[\"Coef\"])\n",
    "\n",
    "        plt.figure(figsize = (10,5))\n",
    "        plt.barh(top[\"Feature\"], top[\"Coef\"])\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"Coef values\")\n",
    "        plt.title(f\"{y_cols[i]}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
